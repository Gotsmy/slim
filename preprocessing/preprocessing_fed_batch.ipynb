{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb41944-aad7-40e7-8fb1-5adab4efe2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10ba4ab-911c-427b-8f36-2c7ab40faff6",
   "metadata": {},
   "source": [
    "# fed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8923853d-24e5-488d-a611-ced44b6c8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '220829_dFBA_exp_feed_v04'\n",
    "loc     = f'/mnt/itching_scratch/mgotsmy/220829_slim_paper_v2/results/{version}.pkl'\n",
    "q_pDNA_min = .1/100\n",
    "special_interest_q_pDNA_max_levels = np.array([1,1.5,2,4])*q_pDNA_min\n",
    "all_q_pDNA_max_levels = np.linspace(.1/100,.5/100,41)\n",
    "# check if special_interest_q_pDNA_max_levels in all_q_pDNA_max_levels\n",
    "for q in special_interest_q_pDNA_max_levels:\n",
    "    if np.any(np.isclose(q,all_q_pDNA_max_levels)):\n",
    "        pass\n",
    "    else:\n",
    "        print('q_pDNA_max = {:6.4f} mmol/(g h) from special interest not in all.'.format(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb5b9110-67f6-47a6-b2ce-7fd40b77f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loc,'rb') as file:\n",
    "    combined_results = pickle.load(file)\n",
    "found_q_pDNA_max_levels = list(combined_results.keys())\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ccfc3a1-2acc-48c3-9e66-0aa9adc9e1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files.\n",
      "All q_pDNA_max levels found.\n",
      "No extra q_pDNA_max levels found.\n"
     ]
    }
   ],
   "source": [
    "# lookup stored files\n",
    "q_pDNA_max_levels_set      = all_q_pDNA_max_levels\n",
    "files_extra                = []\n",
    "all_found_q_pDNA_max_levels = []\n",
    "special_interest_found_q_pDNA_max_levels = []\n",
    "\n",
    "# check if there are extra files or files missing\n",
    "for q_pDNA_max in found_q_pDNA_max_levels:\n",
    "    isclose = np.isclose(q_pDNA_max,q_pDNA_max_levels_set)\n",
    "    if np.any(isclose):\n",
    "        q_pDNA_max_levels_set = q_pDNA_max_levels_set[np.invert(isclose)]\n",
    "        all_found_q_pDNA_max_levels.append(q_pDNA_max)\n",
    "        if np.any(np.isclose(q_pDNA_max,special_interest_q_pDNA_max_levels)):\n",
    "            special_interest_found_q_pDNA_max_levels.append(q_pDNA_max)\n",
    "    else:\n",
    "        files_extra.append([q_pDNA_max])\n",
    "\n",
    "# print results\n",
    "print('Reading files.')\n",
    "if len(q_pDNA_max_levels_set):\n",
    "    print('q_pDNA_max levels not found:')\n",
    "    for q_pDNA_max in sorted(q_pDNA_max_levels_set):\n",
    "        print('{:6.4f}'.format(q_pDNA_max))\n",
    "else:\n",
    "    print('All q_pDNA_max levels found.')\n",
    "if len(files_extra):\n",
    "    print('Extra q_pDNA_max levels found:')\n",
    "    for q_pDNA_max in files_extra:\n",
    "        print('{:6.4f}'.format(q_pDNA_max))\n",
    "else:\n",
    "    print('No extra q_pDNA_max levels found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "180978c6-8e15-4266-bcf7-580c1eb20b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_batch_results_sorter(results):\n",
    "    '''\n",
    "    Sorts results dic according to numeric value in key.\n",
    "    '''\n",
    "    results_sorted = {}\n",
    "    for S_0 in sorted(results):\n",
    "        results_sorted[S_0] = results[S_0]\n",
    "    return results_sorted\n",
    "\n",
    "def fed_batch_unpack_values(sol):\n",
    "    '''\n",
    "    Unpacks concentrations in the sol.y array.\n",
    "    '''\n",
    "    t = sol.t\n",
    "    V = sol.y.T[:,0]\n",
    "    X = sol.y.T[:,1]\n",
    "    S = sol.y.T[:,2]\n",
    "    P = sol.y.T[:,3]\n",
    "    G = sol.y.T[:,4]\n",
    "    return t,V,X,S,P,G\n",
    "\n",
    "def fed_batch_calculate_terminal_idx(sol):\n",
    "    '''\n",
    "    Calculates terminal_idx and start of starvation time.\n",
    "    '''\n",
    "    \n",
    "    t,V,X,S,P,G = fed_batch_unpack_values(sol)\n",
    "    \n",
    "    # find t_starvation_start\n",
    "    s_is_0 = np.isclose(S,0,atol=1e-3)\n",
    "    if np.any(s_is_0):\n",
    "        idx_star_start = np.where(s_is_0)[0][0]           # index of t_starvation_start\n",
    "        t_star_start   = t[idx_star_start]                # value of t_starvation_start\n",
    "        t_star_end     = t[-1]                            # value of t_starvation_end\n",
    "        idx_star_end   = np.argmin(np.abs(t-t_star_end))  # index of t_starvation_end\n",
    "        terminal_idx   = idx_star_end\n",
    "    else:\n",
    "        terminal_idx   = -1\n",
    "        t_star_start   = np.nan\n",
    "            \n",
    "    return terminal_idx, t_star_start\n",
    "\n",
    "def fed_batch_calculate_endpoints(results):\n",
    "    '''\n",
    "    Return concentrations of molecules of interest at the end of a process.\n",
    "    '''\n",
    "    \n",
    "    endpoints = []\n",
    "    for S_0 in sorted(results):\n",
    "        sol = results[S_0]\n",
    "        t,V,X,S,P,G = fed_batch_unpack_values(sol)\n",
    "        terminal_idx, t_star_start = fed_batch_calculate_terminal_idx(sol)\n",
    "        endpoint = [\n",
    "            S_0,\n",
    "            t[terminal_idx],\n",
    "            V[terminal_idx],\n",
    "            X[terminal_idx],\n",
    "            S[terminal_idx],\n",
    "            P[terminal_idx],\n",
    "            G[terminal_idx],\n",
    "            t_star_start\n",
    "        ]\n",
    "        endpoints.append(endpoint)\n",
    "    return np.array(endpoints)\n",
    "\n",
    "def fed_batch_trim_processes(results):\n",
    "    '''\n",
    "    Trim processes of special interest to the calculated process ends.\n",
    "    '''\n",
    "    \n",
    "    trimmed_results = {}\n",
    "    for S_0 in sorted(results):\n",
    "        sol = results[S_0]\n",
    "        t,V,X,S,P,G = fed_batch_unpack_values(sol)\n",
    "        terminal_idx, t_star_start = fed_batch_calculate_terminal_idx(sol)\n",
    "        curves = [\n",
    "            S_0,\n",
    "            t[:terminal_idx],\n",
    "            V[:terminal_idx],\n",
    "            X[:terminal_idx],\n",
    "            S[:terminal_idx],\n",
    "            P[:terminal_idx],\n",
    "            G[:terminal_idx],\n",
    "            t_star_start\n",
    "        ]\n",
    "        trimmed_results[S_0] = curves\n",
    "    return trimmed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e88021eb-bada-49c5-a3ba-d8d3463644a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files.\n",
      "Done.\n",
      "Length processed        =  41\n",
      "Length special interest =   4\n"
     ]
    }
   ],
   "source": [
    "print('Processing files.')\n",
    "processed = {}\n",
    "special_interest = {}\n",
    "for q_pDNA_max in all_found_q_pDNA_max_levels:\n",
    "    results = combined_results[q_pDNA_max]\n",
    "    processed[q_pDNA_max] = fed_batch_calculate_endpoints(results)\n",
    "    if q_pDNA_max in special_interest_found_q_pDNA_max_levels:\n",
    "        special_interest[q_pDNA_max] = fed_batch_trim_processes(results)\n",
    "    # break\n",
    "print('Done.')\n",
    "print('Length processed        = {:3.0f}'.format(len(processed)))\n",
    "print('Length special interest = {:3.0f}'.format(len(special_interest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12dca8f4-a375-4551-98c6-ea644d79793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed file.\n"
     ]
    }
   ],
   "source": [
    "write_loc = f'/home/users/mgotsmy/pdna/220000_notebooks/220829_slim_paper_v2/preprocessing/{version}.pkl'\n",
    "with open(write_loc,'wb') as file:\n",
    "    pickle.dump([processed,special_interest],file)\n",
    "print('Saved processed file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f86aa0-921e-426e-9180-2d9e1a18c7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "097da44b-acab-4e88-af78-5b357e9b5601",
   "metadata": {},
   "source": [
    "## fed_batch v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b80d5fc-0d80-429a-bf04-23f141045b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '220829_dFBA_linear_feed_v05'\n",
    "loc     = f'/mnt/itching_scratch/mgotsmy/220829_slim_paper_v2/results/{version}.pkl'\n",
    "q_pDNA_min = .1/100\n",
    "special_interest_q_pDNA_max_levels = np.array([1,1.5,2,4])*q_pDNA_min\n",
    "all_q_pDNA_max_levels = np.sort(np.append(np.linspace(.1,.11,10)/100,np.linspace(.1,.5,41)/100)) #np.linspace(.1/100,.5/100,41)\n",
    "# check if special_interest_q_pDNA_max_levels in all_q_pDNA_max_levels\n",
    "for q in special_interest_q_pDNA_max_levels:\n",
    "    if np.any(np.isclose(q,all_q_pDNA_max_levels)):\n",
    "        pass\n",
    "    else:\n",
    "        print('q_pDNA_max = {:6.4f} mmol/(g h) from special interest not in all.'.format(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656da708-e447-45ea-ad64-f98915d43293",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loc,'rb') as file:\n",
    "    combined_results = pickle.load(file)\n",
    "found_q_pDNA_max_levels = list(combined_results.keys())\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "063e4745-652f-4d53-bc24-c092cd02e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files.\n",
      "All q_pDNA_max levels found.\n",
      "No extra q_pDNA_max levels found.\n"
     ]
    }
   ],
   "source": [
    "# lookup stored files\n",
    "q_pDNA_max_levels_set      = all_q_pDNA_max_levels\n",
    "files_extra                = []\n",
    "all_found_q_pDNA_max_levels = []\n",
    "special_interest_found_q_pDNA_max_levels = []\n",
    "\n",
    "# check if there are extra files or files missing\n",
    "for q_pDNA_max in found_q_pDNA_max_levels:\n",
    "    isclose = np.isclose(q_pDNA_max,q_pDNA_max_levels_set)\n",
    "    if np.any(isclose):\n",
    "        q_pDNA_max_levels_set = q_pDNA_max_levels_set[np.invert(isclose)]\n",
    "        all_found_q_pDNA_max_levels.append(q_pDNA_max)\n",
    "        if np.any(np.isclose(q_pDNA_max,special_interest_q_pDNA_max_levels)):\n",
    "            special_interest_found_q_pDNA_max_levels.append(q_pDNA_max)\n",
    "    else:\n",
    "        files_extra.append([q_pDNA_max])\n",
    "\n",
    "# print results\n",
    "print('Reading files.')\n",
    "if len(q_pDNA_max_levels_set):\n",
    "    print('q_pDNA_max levels not found:')\n",
    "    for q_pDNA_max in sorted(q_pDNA_max_levels_set):\n",
    "        print('{:6.4f}'.format(q_pDNA_max))\n",
    "else:\n",
    "    print('All q_pDNA_max levels found.')\n",
    "if len(files_extra):\n",
    "    print('Extra q_pDNA_max levels found:')\n",
    "    for q_pDNA_max in files_extra:\n",
    "        print('{:6.4f}'.format(q_pDNA_max))\n",
    "else:\n",
    "    print('No extra q_pDNA_max levels found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482792ae-981c-4f25-9f5c-b4dadfc424ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_batch_results_sorter_v2(results):\n",
    "    '''\n",
    "    Sorts results dic according to numeric value in key.\n",
    "    '''\n",
    "    results_sorted = {}\n",
    "    for S_0 in sorted(results):\n",
    "        results_sorted[S_0] = results[S_0]\n",
    "    return results_sorted\n",
    "\n",
    "def fed_batch_unpack_values_v2(sol):\n",
    "    '''\n",
    "    Unpacks concentrations in the sol.y array.\n",
    "    '''\n",
    "    t = sol.t\n",
    "    V = sol.y.T[:,0]\n",
    "    X = sol.y.T[:,1]\n",
    "    S = sol.y.T[:,2]\n",
    "    P = sol.y.T[:,3]\n",
    "    G = sol.y.T[:,4]\n",
    "    return t,V,X,S,P,G\n",
    "\n",
    "def fed_batch_calculate_terminal_idx_v2(sol):\n",
    "    '''\n",
    "    Calculates terminal_idx and start of starvation time.\n",
    "    '''\n",
    "    \n",
    "    t,V,X,S,P,G = fed_batch_unpack_values_v2(sol)\n",
    "    \n",
    "    # find t_starvation_start\n",
    "    s_is_0 = np.isclose(S,0,atol=1e-3)\n",
    "    if np.any(s_is_0):\n",
    "        idx_star_start = np.where(s_is_0)[0][0]           # index of t_starvation_start\n",
    "        t_star_start   = t[idx_star_start]                # value of t_starvation_start\n",
    "        t_star_end     = t[-1]                            # value of t_starvation_end\n",
    "        idx_star_end   = np.argmin(np.abs(t-t_star_end))  # index of t_starvation_end\n",
    "        terminal_idx   = idx_star_end\n",
    "    else:\n",
    "        terminal_idx   = -1\n",
    "        t_star_start   = np.nan\n",
    "            \n",
    "    return terminal_idx, t_star_start\n",
    "\n",
    "def fed_batch_calculate_endpoints_v2(results):\n",
    "    '''\n",
    "    Return concentrations of molecules of interest at the end of a process.\n",
    "    '''\n",
    "    \n",
    "    tmp = results[list(results.keys())[-1]]\n",
    "    t,V,X,S,P,G = fed_batch_unpack_values_v2(tmp)\n",
    "    no_starv_productivity = P[-1]/V[-1]/t[-1]\n",
    "    \n",
    "    endpoints = []\n",
    "    for S_0 in sorted(results):\n",
    "        sol = results[S_0]\n",
    "        terminal_idx, t_star_start = fed_batch_calculate_terminal_idx_v2(sol)\n",
    "        \n",
    "        t,V,X,S,P,G = fed_batch_unpack_values_v2(sol)\n",
    "        # productivity_time_series = P/V/(t+1e-8)\n",
    "        productivity_time_series = P/V/t[terminal_idx]\n",
    "        t_end_min = t[np.argmin(np.abs(np.nan_to_num(productivity_time_series-no_starv_productivity,nan=1000)))]\n",
    "        endpoint = [\n",
    "            S_0,\n",
    "            t[terminal_idx],\n",
    "            V[terminal_idx],\n",
    "            X[terminal_idx],\n",
    "            S[terminal_idx],\n",
    "            P[terminal_idx],\n",
    "            G[terminal_idx],\n",
    "            t_star_start,\n",
    "            t_end_min\n",
    "        ]\n",
    "        endpoints.append(endpoint)\n",
    "    return np.array(endpoints)\n",
    "\n",
    "def fed_batch_trim_processes_v2(results):\n",
    "    '''\n",
    "    Trim processes of special interest to the calculated process ends.\n",
    "    '''\n",
    "    \n",
    "    trimmed_results = {}\n",
    "    for S_0 in sorted(results):\n",
    "        sol = results[S_0]\n",
    "        t,V,X,S,P,G = fed_batch_unpack_values_v2(sol)\n",
    "        terminal_idx, t_star_start = fed_batch_calculate_terminal_idx_v2(sol)\n",
    "        curves = [\n",
    "            S_0,\n",
    "            t[:terminal_idx],\n",
    "            V[:terminal_idx],\n",
    "            X[:terminal_idx],\n",
    "            S[:terminal_idx],\n",
    "            P[:terminal_idx],\n",
    "            G[:terminal_idx],\n",
    "            t_star_start\n",
    "        ]\n",
    "        trimmed_results[S_0] = curves\n",
    "    return trimmed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcde846-67d4-4e32-a9db-60b6bd02f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files.\n",
      "Done.\n",
      "Length processed        =  49\n",
      "Length special interest =   4\n"
     ]
    }
   ],
   "source": [
    "print('Processing files.')\n",
    "processed = {}\n",
    "special_interest = {}\n",
    "for q_pDNA_max in all_found_q_pDNA_max_levels:\n",
    "    results = combined_results[q_pDNA_max]\n",
    "    processed[q_pDNA_max] = fed_batch_calculate_endpoints_v2(results)\n",
    "    if q_pDNA_max in special_interest_found_q_pDNA_max_levels:\n",
    "        special_interest[q_pDNA_max] = fed_batch_trim_processes_v2(results)\n",
    "    # break\n",
    "print('Done.')\n",
    "print('Length processed        = {:3.0f}'.format(len(processed)))\n",
    "print('Length special interest = {:3.0f}'.format(len(special_interest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37311d88-cd04-4a00-a31d-b7fdff855cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed file.\n"
     ]
    }
   ],
   "source": [
    "write_loc = f'/home/users/mgotsmy/pdna/220000_notebooks/220829_slim_paper_v2/preprocessing/{version}_v2.pkl'\n",
    "with open(write_loc,'wb') as file:\n",
    "    pickle.dump([processed,special_interest],file)\n",
    "print('Saved processed file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efdab9-487e-4e1f-8502-a52467533136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2206test3.10",
   "language": "python",
   "name": "2206test3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
